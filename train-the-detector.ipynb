{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user tflearn\n",
    "#!pip install --user librosa 'llvmlite==0.19.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 7, dict_keys(['1', '2', '3', '4', '5', '6', 'sil']), (16, 40))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "from tflearn.data_utils import to_categorical\n",
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "import glob\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "dataset = []\n",
    "label_to_idx = dict()\n",
    "idx_to_label = dict()\n",
    "time_size = 16\n",
    "feat_size = 40\n",
    "\n",
    "rate, noise_data = wavfile.read('dataset/noise.wav')\n",
    "noise_rest = len(noise_data) - rate\n",
    "\n",
    "def normalize(data):\n",
    "    data = data.astype(float)\n",
    "    mn, mx = data.min(), data.max()\n",
    "    data = (data - mn) / (mx - mn) * 65535 - 32768\n",
    "    return data.astype('short')\n",
    "\n",
    "def read_dataset():\n",
    "    for fname in glob.glob('dataset/*/*.wav', recursive=True):\n",
    "        label = fname.split('.')[0].split('/')[1:]\n",
    "        rate, data = wavfile.read(fname)\n",
    "        data = normalize(data)\n",
    "        yield label, data\n",
    "\n",
    "def augment_and_pad_dataset(dataset):\n",
    "    for info, data in dataset:\n",
    "        for _ in range(8):\n",
    "            file_rest = rate - len(data)\n",
    "            if file_rest <= 0:\n",
    "                file_data = data[:rate]\n",
    "            else:\n",
    "                file_offset = int(random.uniform(0, file_rest))\n",
    "                file_data = np.pad(data, (file_offset, file_rest - file_offset), 'constant', constant_values=(0,0))\n",
    "            for noise_level in range(4):\n",
    "                noise_offset = int(random.uniform(0, noise_rest))\n",
    "                noise_sample = noise_data[noise_offset:noise_offset + rate] * noise_level\n",
    "                file_data += noise_sample\n",
    "                yield (*info, noise_level), file_data\n",
    "\n",
    "for info, data in augment_and_pad_dataset(read_dataset()):\n",
    "#     wavfile.write('temp/%s.wav' % (info,), rate, data)\n",
    "\n",
    "    mfcc = np.transpose(librosa.feature.mfcc(data, rate, n_mfcc=feat_size))\n",
    "\n",
    "    label = info[0]\n",
    "    idx = label_to_idx.get(label, None)\n",
    "    if idx is None:\n",
    "        idx = len(label_to_idx)\n",
    "        label_to_idx[label] = idx\n",
    "        idx_to_label[idx] = label\n",
    "    dataset.append((mfcc, idx, info))\n",
    "random.shuffle(dataset)\n",
    "\n",
    "inp_data = [r[0] for r in dataset]\n",
    "out_size = len(label_to_idx)\n",
    "out_data = to_categorical([r[1] for r in dataset], out_size)\n",
    "\n",
    "len(inp_data), out_size, label_to_idx.keys(), inp_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.19588\u001b[0m\u001b[0m | time: 2.944s\n",
      "\u001b[2K\r",
      "| Adam | epoch: 020 | loss: 0.19588 - acc: 0.9747 -- iter: 876/876\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.layers.recurrent import bidirectional_rnn, BasicLSTMCell\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "check_size = 20 #int(len(inp_data) * 0.1)\n",
    "learn_size = len(inp_data) - check_size\n",
    "trainX = inp_data[:learn_size]\n",
    "trainY = out_data[:learn_size]\n",
    "testX = inp_data[-check_size:]\n",
    "testY = out_data[-check_size:]\n",
    "\n",
    "g = tflearn.input_data(shape=[None,time_size,feat_size])\n",
    "\n",
    "g = tflearn.reshape(g, [-1,time_size,feat_size,1])\n",
    "g = tflearn.conv_2d(g, 64, (20,8), activation='relu')\n",
    "g = tflearn.max_pool_2d(g, 3, strides=2)\n",
    "g = tflearn.local_response_normalization(g)\n",
    "g = tflearn.reshape(g, [-1,time_size,feat_size*16])\n",
    "\n",
    "g = tflearn.gru(g, 256, dropout=0.7)\n",
    "\n",
    "g = tflearn.fully_connected(g, out_size, activation='softmax')\n",
    "g = tflearn.regression(g, optimizer='adam', loss='categorical_crossentropy', learning_rate=0.001)\n",
    "m = tflearn.DNN(g)\n",
    "m.fit(trainX, trainY, n_epoch=20, show_metric=True, snapshot_epoch=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ 9% 3: ('3', 'a', 0)\n",
      "+ 9% sil: ('sil', 'a', 3)\n",
      "+ 9% 1: ('1', 'a', 0)\n",
      "+ 9% 2: ('2', 'c', 3)\n",
      "+ 9% sil: ('sil', 'b', 3)\n",
      "+ 9% 6: ('6', 'b', 1)\n",
      "+ 9% sil: ('sil', 'c', 1)\n",
      "+ 9% 3: ('3', 'b', 0)\n",
      "+ 9% 3: ('3', 'c', 0)\n",
      "+ 9% 1: ('1', 'e', 2)\n",
      "+ 9% 1: ('1', 'd', 0)\n",
      "+ 9% 1: ('1', 'b', 3)\n",
      "+ 8% 3: ('3', 'b', 2)\n",
      "+ 9% 1: ('1', 'c', 2)\n",
      "+ 9% 4: ('4', 'b', 2)\n",
      "+ 9% 2: ('2', 'd', 3)\n",
      "+ 9% 2: ('2', 'c', 2)\n",
      "+ 9% 3: ('3', 'a', 0)\n",
      "+ 9% 2: ('2', 'e', 3)\n",
      "+ 8% 1: ('1', 'a', 1)\n",
      "20 0 0 8\n",
      "---\n",
      "v 9 sil ('sil', 'f', 2)\n",
      "v 9 3 ('3', 'b', 3)\n",
      "v 9 sil ('sil', 'f', 1)\n",
      "v 9 4 ('4', 'a', 3)\n",
      "v 9 sil ('sil', 'a', 0)\n",
      "v 9 sil ('sil', 'b', 3)\n",
      "v 9 1 ('1', 'e', 3)\n",
      "v 9 6 ('6', 'a', 3)\n",
      "v 9 1 ('1', 'b', 3)\n",
      "v 9 5 ('5', 'b', 1)\n",
      "v 9 1 ('1', 'd', 1)\n",
      "v 9 sil ('sil', 'g', 3)\n",
      "v 9 3 ('3', 'e', 0)\n",
      "v 9 1 ('1', 'b', 1)\n",
      "v 9 sil ('sil', 'c', 2)\n",
      "v 9 6 ('6', 'a', 2)\n",
      "v 9 sil ('sil', 'a', 0)\n",
      "v 9 4 ('4', 'a', 3)\n",
      "v 9 4 ('4', 'a', 0)\n",
      "v 9 1 ('1', 'a', 3)\n",
      "v 9 1 ('1', 'b', 0)\n",
      "v 9 2 ('2', 'c', 1)\n",
      "v 9 sil ('sil', 'g', 0)\n",
      "v 9 4 ('4', 'b', 2)\n",
      "v 9 3 ('3', 'e', 3)\n",
      "v 9 1 ('1', 'b', 3)\n",
      "v 9 2 ('2', 'd', 2)\n",
      "v 9 sil ('sil', 'e', 0)\n",
      "v 9 3 ('3', 'a', 1)\n",
      "v 9 sil ('sil', 'g', 1)\n",
      "v 9 6 ('6', 'b', 3)\n",
      "v 9 2 ('2', 'd', 2)\n",
      "v 9 2 ('2', 'e', 1)\n",
      "v 9 5 ('5', 'b', 3)\n",
      "v 9 3 ('3', 'd', 1)\n",
      "v 9 1 ('1', 'd', 2)\n",
      "v 8 2 ('2', 'c', 3)\n",
      "v 9 2 ('2', 'b', 3)\n",
      "v 9 6 ('6', 'b', 0)\n",
      "v 9 3 ('3', 'e', 1)\n"
     ]
    }
   ],
   "source": [
    "hits, miss = 0, 0\n",
    "mxpe, mnpv = 0, 10\n",
    "for i, out in enumerate(m.predict(testX)):\n",
    "    i0 = out.argsort()[-1]\n",
    "    lbl = idx_to_label[i0]\n",
    "    info = dataset[learn_size + i][2]\n",
    "    l, v, n = info\n",
    "    p = int(out[i0]*10)\n",
    "    ok = l == lbl\n",
    "    if ok:\n",
    "        hits += 1\n",
    "        mnpv = min(mnpv, p)\n",
    "    else:\n",
    "        miss += 1\n",
    "        mxpe = max(mxpe, p)\n",
    "    print('%s %d%% %s: %s' % (('+' if ok else '-'), p, lbl, info))\n",
    "print(hits, miss, mxpe, mnpv)\n",
    "print('---')\n",
    "for f, _, info in dataset[100:140]:\n",
    "    out = m.predict([f])[0]\n",
    "    i0 = out.argsort()[-1]\n",
    "    lbl = idx_to_label[i0]\n",
    "    print(('v' if info[0] == lbl else '-'), int(out[i0]*10), lbl, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986017 3\n",
      "0.9848 3\n",
      "0.986238 3\n",
      "0.989401 3\n"
     ]
    }
   ],
   "source": [
    "rate, wave = wavfile.read('dataset/sil/a.wav')\n",
    "rate, wave = wavfile.read('test3.wav')\n",
    "wave = normalize(wave)\n",
    "f = np.transpose(librosa.feature.mfcc(wave, rate, n_mfcc=feat_size))\n",
    "for i in range(0, f.shape[0] - time_size + 1):\n",
    "    unt=f[i:i+time_size]\n",
    "    for out in m.predict([unt]):\n",
    "        i0 = out.argsort()[-1]\n",
    "        lbl = idx_to_label[i0]\n",
    "        print(out[i0], lbl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
